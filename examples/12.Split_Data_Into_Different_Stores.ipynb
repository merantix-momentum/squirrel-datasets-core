{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xd4DVhIQUXG-"
   },
   "source": [
    "Sometimes, it is usefull to store your data into different stores based on a categorical label of your data. In this notebook, we demonstrate how this can be done using the additional help of Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LQbGHY75apkJ"
   },
   "outputs": [],
   "source": [
    "!pip install squirrel-core pyspark\n",
    "!pip install more-itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1120,
     "status": "ok",
     "timestamp": 1669640239298,
     "user": {
      "displayName": "Pengfei Zhao",
      "userId": "14353614029212480116"
     },
     "user_tz": -60
    },
    "id": "7jFgTFT-bV7Q"
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from random import randint\n",
    "from functools import partial\n",
    "from pyspark.sql import SparkSession\n",
    "from squirrel.store import SquirrelStore\n",
    "from squirrel.serialization import MessagepackSerializer\n",
    "from squirrel.iterstream import IterableSource, FilePathGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10762,
     "status": "ok",
     "timestamp": 1669640281752,
     "user": {
      "displayName": "Pengfei Zhao",
      "userId": "14353614029212480116"
     },
     "user_tz": -60
    },
    "id": "OmcD5juDTE74",
    "outputId": "7b96955b-4a50-4e48-a6eb-7d40e8bb6794"
   },
   "outputs": [],
   "source": [
    "def generate_categorical_samples(N):\n",
    "    \"\"\"Generate data where the uid field is used as a categorical label to split\"\"\"\n",
    "    return [{\"uid\": randint(1, 10), \"data\": 0} for _ in range(N)]\n",
    "\n",
    "\n",
    "def save_shards(tuple_, shard_size, uri):\n",
    "    \"\"\"Used as a partial function to save the data into a different store based on the uid\"\"\"\n",
    "    key = tuple_[0]\n",
    "    store = SquirrelStore(url=f\"{uri}/{key}\", serializer=MessagepackSerializer())\n",
    "    iterab = tuple_[1]\n",
    "    store.set(value=iterab, key=key)\n",
    "\n",
    "\n",
    "N_SHARDS = 50\n",
    "# Generate samples\n",
    "samples = IterableSource(generate_categorical_samples(100))\n",
    "\n",
    "# Initiate Spark\n",
    "spark = SparkSession.builder.appName(\"test\").getOrCreate()\n",
    "rdd = spark.sparkContext.parallelize(samples)\n",
    "with tempfile.TemporaryDirectory() as tempdir:\n",
    "\n",
    "    def to_list(a):\n",
    "        return [a]\n",
    "\n",
    "    def append(a, b):\n",
    "        a.append(b)\n",
    "        return a\n",
    "\n",
    "    def extend(a, b):\n",
    "        a.extend(b)\n",
    "        return a\n",
    "\n",
    "    _ = (\n",
    "        rdd.map(lambda x: (x[\"uid\"], x))\n",
    "        .combineByKey(to_list, append, extend)\n",
    "        .foreach(partial(save_shards, uri=f\"{tempdir}\", shard_size=100))\n",
    "    )\n",
    "    # We can see that each uid now has its own storage URI\n",
    "    print(FilePathGenerator(tempdir, nested=True).collect())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
